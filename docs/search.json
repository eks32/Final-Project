[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "This exploratory data analysis investigates the [CDC Diabetes Dataset] (https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) to understand factors associated with diabetes prevalence. We want to find which biological and lifestyle factors can influence diabetes. Primarily the variables we were interested in were: -If the participant has High Blood Pressure (Yes/No) -If the participant has High Cholesterol (Yes/No) -If the participant does physical activity (Yes/No) -The participant’s BMI (Integer) -The participant’s Age (Integer) -The participant’s Gender (M/F) -The participants perception of their overall health\nThese factors are analyzed to explore their relationships with the binary outcome variable, Diabetes_binary, which indicates the presence or absence of diabetes. By examining these variables, this analysis aims to uncover patterns and insights that may inform predictive modeling for diabetes risk.\n\n#Loading Libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\n\n#Loading our data.\nbeetus_data&lt;-read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Changing to factors and adding names.  \nbeetus_data &lt;- beetus_data |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, labels = c(\"No Diabetes\", \"Pre/Diabetes\")),\n    HighBP = factor(HighBP, labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, labels = c(\"No High Cholesterol\", \"High Cholesterol\")),\n    Smoker = factor(Smoker, labels = c(\"Non-Smoker\", \"Smoker\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No Physical Activity\", \"Physical Activity\")),\n\n    Sex = factor(Sex, labels = c(\"Female\", \"Male\")),\n    GenHlth = factor(GenHlth, levels=1:5, labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    Education = factor(Education,levels=1:6, labels = c(\n      \"Never Attended School or only kindergarten\",\n      \"Grades 1-8\",\n      \"Grades 9-11\",\n      \"Grade 12/GED\",\n      \"Some College/Technical School\",\n      \"College Graduate\"\n    )),\n    Income = factor(Income,levels=1:8, labels = c(\n      \"Less than $10,000\",\n      \"$10,000 to $15,000\",\n      \"$15,000 to $20,000\",\n      \"$20,000 to $25,000\",\n      \"$25,000 to $35,000\",\n      \"$35,000 to $50,000\",\n      \"$50,000 to $75,000\",\n      \"$75,000 or more\"\n    )),\n    Age = factor(Age,levels=1:13, labels = c(\n      \"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n      \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\",\n      \"70-74\", \"75-79\", \"80 or older\"\n    ))\n  )\n#Variables we're interested in\nbeetus_filtered &lt;- beetus_data |&gt;\n  select(Diabetes_binary,HighBP,HighChol,PhysActivity,BMI,Age,Sex,GenHlth)\n\nLet’s take a look at the structure of our data and check if there’s any missing values.\n\n#Quick look at data types\nstr(beetus_filtered)\n\ntibble [253,680 × 8] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary: Factor w/ 2 levels \"No Diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP         : Factor w/ 2 levels \"No High BP\",\"High BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol       : Factor w/ 2 levels \"No High Cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ PhysActivity   : Factor w/ 2 levels \"No Physical Activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ BMI            : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Age            : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Sex            : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ GenHlth        : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n\n#Checking for Missing Data\nbeetus_filtered |&gt;\n  is.na()|&gt;\n  colSums()\n\nDiabetes_binary          HighBP        HighChol    PhysActivity             BMI \n              0               0               0               0               0 \n            Age             Sex         GenHlth \n              0               0               0 \n\n\nNo missing values. Let’s check some numerical summaries for BMI."
  },
  {
    "objectID": "EDA.html#quarto",
    "href": "EDA.html#quarto",
    "title": "EDA",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.3.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'broom' was built under R version 4.3.3\n\n\nWarning: package 'dials' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.3\n\n\nWarning: package 'infer' was built under R version 4.3.3\n\n\nWarning: package 'modeldata' was built under R version 4.3.3\n\n\nWarning: package 'parsnip' was built under R version 4.3.3\n\n\nWarning: package 'recipes' was built under R version 4.3.3\n\n\nWarning: package 'rsample' was built under R version 4.3.3\n\n\nWarning: package 'tune' was built under R version 4.3.3\n\n\nWarning: package 'workflows' was built under R version 4.3.3\n\n\nWarning: package 'workflowsets' was built under R version 4.3.3\n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nbeetus_data&lt;-read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbeetus_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(ranger)\nlibrary(parallel)\nlibrary(plumber)"
  },
  {
    "objectID": "Modeling.html#quarto",
    "href": "Modeling.html#quarto",
    "title": "Modeling",
    "section": "",
    "text": "Click here for the EDA"
  },
  {
    "objectID": "EDA.html#exploration",
    "href": "EDA.html#exploration",
    "title": "EDA",
    "section": "",
    "text": "Let’s take a look at our data. Let’s start with looking at the data/variable types and checking for missing values.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\n\n\nbeetus_data&lt;-read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Quick look at data types\nstr(beetus_data)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#Checking for Missing Data\nbeetus_data |&gt;\n  is.na()|&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThere seems to be no missing values. Based on the look at structure, we might have some factor variables. Before that though, checking a quick summary for our variables.\n\nsummary(beetus_data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nLooks like we have some factors. Checking for unique values.\n\nbeetus_data |&gt;\n  summarise(across(everything(), ~ list(unique(.))))\n\n# A tibble: 1 × 22\n  Diabetes_binary HighBP    HighChol  CholCheck BMI        Smoker    Stroke   \n  &lt;list&gt;          &lt;list&gt;    &lt;list&gt;    &lt;list&gt;    &lt;list&gt;     &lt;list&gt;    &lt;list&gt;   \n1 &lt;dbl [2]&gt;       &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt; &lt;dbl [84]&gt; &lt;dbl [2]&gt; &lt;dbl [2]&gt;\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;list&gt;, PhysActivity &lt;list&gt;,\n#   Fruits &lt;list&gt;, Veggies &lt;list&gt;, HvyAlcoholConsump &lt;list&gt;,\n#   AnyHealthcare &lt;list&gt;, NoDocbcCost &lt;list&gt;, GenHlth &lt;list&gt;, MentHlth &lt;list&gt;,\n#   PhysHlth &lt;list&gt;, DiffWalk &lt;list&gt;, Sex &lt;list&gt;, Age &lt;list&gt;, Education &lt;list&gt;,\n#   Income &lt;list&gt;\n\n\nLooks like we do have multiple factors. &lt;dbl[2]&gt;s are binary values. Education/income seem to be factors as well. Going to the dataset’s source website: CDC Diabetes Health Dataset\n\nbeetus_data &lt;- beetus_data |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, levels=c(0,1), labels = c(\"No Diabetes\", \"Pre/Diabetes\")),\n    HighBP = factor(HighBP, labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, labels = c(\"No High Cholesterol\", \"High Cholesterol\")),\n    CholCheck = factor(CholCheck, labels = c(\"No Cholesterol Check\", \"Cholesterol Check\")),\n    Smoker = factor(Smoker, labels = c(\"Non-Smoker\", \"Smoker\")),\n    Stroke = factor(Stroke, labels = c(\"No Stroke\", \"Stroke\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No Physical Activity\", \"Physical Activity\")),\n    Fruits = factor(Fruits, labels = c(\"No\", \"Yes\")),\n    Veggies = factor(Veggies, labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, labels = c(\"No\", \"Yes\")),\n    AnyHealthcare = factor(AnyHealthcare, labels = c(\"No\", \"Yes\")),\n    NoDocbcCost = factor(NoDocbcCost, labels = c(\"No\", \"Yes\")),\n    DiffWalk = factor(DiffWalk, labels = c(\"No\", \"Yes\")),\n    Sex = factor(Sex, labels = c(\"Female\", \"Male\")),\n    GenHlth = factor(GenHlth, labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    Education = factor(Education, labels = c(\n      \"Never Attended School or only kindergarten\",\n      \"Grades 1-8\",\n      \"Grades 9-11\",\n      \"Grade 12/GED\",\n      \"Some College/Technical School\",\n      \"College Graduate\"\n    )),\n    Income = factor(Income, labels = c(\n      \"Less than $10,000\",\n      \"$10,000 to $15,000\",\n      \"$15,000 to $20,000\",\n      \"$20,000 to $25,000\",\n      \"$25,000 to $35,000\",\n      \"$35,000 to $50,000\",\n      \"$50,000 to $75,000\",\n      \"$75,000 or more\"\n    )),\n    Age = factor(Age, labels = c(\n      \"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n      \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\",\n      \"70-74\", \"75-79\", \"80 or older\"\n    ))\n  )\nstr(beetus_data)\n\ntibble [253,680 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"No Diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"No High BP\",\"High BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No High Cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"No Cholesterol Check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"Non-Smoker\",\"Smoker\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No Stroke\",\"Stroke\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No Physical Activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never Attended School or only kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"Less than $10,000\",..: 3 1 8 6 4 8 7 4 1 3 ...\n\n\n18 Categorical Variables and 3 Numerical variables. Now our data is tidy, let’s make some contingency tables since we have a bunch of factors.\n\ncont_tables &lt;- lapply(names(beetus_data)[-which(names(beetus_data) == \"Diabetes_binary\")], function(var) {\n  table(beetus_data[[var]], beetus_data$Diabetes_binary)\n})\n\nnames(cont_tables) &lt;- names(beetus_data)[-which(names(beetus_data) == \"Diabetes_binary\")]\n\ncont_tables\n\n$HighBP\n            \n             No Diabetes Pre/Diabetes\n  No High BP      136109         8742\n  High BP          82225        26604\n\n$HighChol\n                     \n                      No Diabetes Pre/Diabetes\n  No High Cholesterol      134429        11660\n  High Cholesterol          83905        23686\n\n$CholCheck\n                      \n                       No Diabetes Pre/Diabetes\n  No Cholesterol Check        9229          241\n  Cholesterol Check         209105        35105\n\n$BMI\n    \n     No Diabetes Pre/Diabetes\n  12           6            0\n  13          19            2\n  14          37            4\n  15         120           12\n  16         328           20\n  17         728           48\n  18        1720           83\n  19        3833          135\n  20        6086          241\n  21        9376          479\n  22       12952          691\n  23       14697          913\n  24       18081         1469\n  25       15695         1451\n  26       18560         2002\n  27       21849         2757\n  28       14294         2251\n  29       12659         2231\n  30       12251         2322\n  31       10163         2112\n  32        8354         2120\n  33        6908         2040\n  34        5494         1687\n  35        4131         1444\n  36        3393         1240\n  37        3029         1118\n  38        2385         1012\n  39        2056          855\n  40        1534          724\n  41        1141          518\n  42        1127          512\n  43         989          511\n  44         697          346\n  45         517          302\n  46         471          279\n  47         404          218\n  48         304          180\n  49         250          166\n  50         224          148\n  51         155           98\n  52         129           86\n  53         152           85\n  54          65           48\n  55         104           65\n  56          66           43\n  57          61           25\n  58          36           35\n  59          32           22\n  60          38           25\n  61          21           14\n  62          27           16\n  63          16           18\n  64          16            8\n  65           9           10\n  66           4            9\n  67           9            6\n  68           8            6\n  69           6            3\n  70          10            5\n  71          44            5\n  72           7            7\n  73          44            3\n  74          15            1\n  75          46            6\n  76           3            0\n  77          48            7\n  78           0            1\n  79          62            4\n  80           1            1\n  81          42            7\n  82          31            6\n  83           1            1\n  84          39            5\n  85           0            1\n  86           1            0\n  87          52            9\n  88           2            0\n  89          25            3\n  90           1            0\n  91           1            0\n  92          27            5\n  95          11            1\n  96           1            0\n  98           4            3\n\n$Smoker\n            \n             No Diabetes Pre/Diabetes\n  Non-Smoker      124228        17029\n  Smoker           94106        18317\n\n$Stroke\n           \n            No Diabetes Pre/Diabetes\n  No Stroke      211310        32078\n  Stroke           7024         3268\n\n$HeartDiseaseorAttack\n     \n      No Diabetes Pre/Diabetes\n  No       202319        27468\n  Yes       16015         7878\n\n$PhysActivity\n                      \n                       No Diabetes Pre/Diabetes\n  No Physical Activity       48701        13059\n  Physical Activity         169633        22287\n\n$Fruits\n     \n      No Diabetes Pre/Diabetes\n  No        78129        14653\n  Yes      140205        20693\n\n$Veggies\n     \n      No Diabetes Pre/Diabetes\n  No        39229         8610\n  Yes      179105        26736\n\n$HvyAlcoholConsump\n     \n      No Diabetes Pre/Diabetes\n  No       204910        34514\n  Yes       13424          832\n\n$AnyHealthcare\n     \n      No Diabetes Pre/Diabetes\n  No        10995         1422\n  Yes      207339        33924\n\n$NoDocbcCost\n     \n      No Diabetes Pre/Diabetes\n  No       200722        31604\n  Yes       17612         3742\n\n$GenHlth\n           \n            No Diabetes Pre/Diabetes\n  Excellent       44159         1140\n  Very Good       82703         6381\n  Good            62189        13457\n  Fair            21780         9790\n  Poor             7503         4578\n\n$MentHlth\n    \n     No Diabetes Pre/Diabetes\n  0       152277        23403\n  1         7726          812\n  2        11546         1508\n  3         6457          924\n  4         3300          489\n  5         7807         1223\n  6          824          164\n  7         2695          405\n  8          529          110\n  9           78           13\n  10        5309         1064\n  11          38            3\n  12         331           67\n  13          33            8\n  14         969          198\n  15        4482         1023\n  16          74           14\n  17          43           11\n  18          77           20\n  19          12            4\n  20        2701          663\n  21         179           48\n  22          52           11\n  23          30            8\n  24          27            6\n  25         915          273\n  26          38            7\n  27          67           12\n  28         270           57\n  29         128           30\n  30        9320         2768\n\n$PhysHlth\n    \n     No Diabetes Pre/Diabetes\n  0       143312        16740\n  1        10200         1188\n  2        12736         2028\n  3         7206         1289\n  4         3779          763\n  5         6308         1314\n  6         1048          282\n  7         3795          743\n  8          650          159\n  9          143           36\n  10        4305         1290\n  11          48           12\n  12         449          129\n  13          52           16\n  14        2114          473\n  15        3621         1295\n  16          78           34\n  17          69           27\n  18         117           35\n  19          19            3\n  20        2356          917\n  21         524          139\n  22          47           23\n  23          40           16\n  24          57           15\n  25         942          394\n  26          47           22\n  27          78           21\n  28         379          143\n  29         141           74\n  30       13674         5726\n\n$DiffWalk\n     \n      No Diabetes Pre/Diabetes\n  No       188780        22225\n  Yes       29554        13121\n\n$Sex\n        \n         No Diabetes Pre/Diabetes\n  Female      123563        18411\n  Male         94771        16935\n\n$Age\n             \n              No Diabetes Pre/Diabetes\n  18-24              5622           78\n  25-29              7458          140\n  30-34             10809          314\n  35-39             13197          626\n  40-44             15106         1051\n  45-49             18077         1742\n  50-54             23226         3088\n  55-59             26569         4263\n  60-64             27511         5733\n  65-69             25636         6558\n  70-74             18392         5141\n  75-79             12577         3403\n  80 or older       14154         3209\n\n$Education\n                                            \n                                             No Diabetes Pre/Diabetes\n  Never Attended School or only kindergarten         127           47\n  Grades 1-8                                        2860         1183\n  Grades 9-11                                       7182         2296\n  Grade 12/GED                                     51684        11066\n  Some College/Technical School                    59556        10354\n  College Graduate                                 96925        10400\n\n$Income\n                    \n                     No Diabetes Pre/Diabetes\n  Less than $10,000         7428         2383\n  $10,000 to $15,000        8697         3086\n  $15,000 to $20,000       12426         3568\n  $20,000 to $25,000       16081         4054\n  $25,000 to $35,000       21379         4504\n  $35,000 to $50,000       31179         5291\n  $50,000 to $75,000       37954         5265\n  $75,000 or more          83190         7195\n\n\nLet’s make some graphs as well.\n#distributions for bmi/age etc…\n\n#Showing plots of variables with 2 factor levels\ntwofact_plot&lt;- beetus_data |&gt;\n  #Select variables with only 2 factor levels for clean plotting\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) == 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n#some scaling issues\nggplot(twofact_plot, aes(x = Value, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~ Variable, scales = \"free_x\") + \n  #tilted for readability\n  theme(axis.text.x = element_text(angle = 10))\n\n\n\n\n\n\n\n#Plots for more than 2 factor levels\nmultifact_data &lt;- beetus_data |&gt;\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) &gt; 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n# Create individual plots for each variable\nplots &lt;- list() # Empty list to store plots\n# Get unique variable names\nunique_variables &lt;- unique(multifact_data$Variable) \nfor (var in unique_variables) {\n  plot &lt;- multifact_data |&gt;\n    filter(Variable == var) |&gt; \n    ggplot(aes(x = Value, fill = Diabetes_binary)) +\n    geom_bar(position = \"dodge\") +\n    theme(axis.text.x = element_text(angle = 10))\n  # Store the plot in the list\n  plots[[var]] &lt;- plot\n}\nplots[[unique_variables[1]]]\n\n\n\n\n\n\n\nplots[[unique_variables[2]]]\n\n\n\n\n\n\n\nplots[[unique_variables[3]]]\n\n\n\n\n\n\n\nplots[[unique_variables[4]]]\n\n\n\n\n\n\n\n\n\n#Correlation Matrix\nbeetus_data |&gt;\nselect(where(is.numeric)) |&gt;\ncor() |&gt;\nround(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA",
    "section": "",
    "text": "This exploratory data analysis investigates the [CDC Diabetes Dataset] (https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) to understand factors associated with diabetes prevalence. We want to find which biological and lifestyle factors can influence diabetes. Primarily the variables we were interested in were: -If the participant has High Blood Pressure (Yes/No) -If the participant has High Cholesterol (Yes/No) -If the participant does physical activity (Yes/No) -The participant’s BMI (Integer) -The participant’s Age (Integer) -The participant’s Gender (M/F) -The participants perception of their overall health\nThese factors are analyzed to explore their relationships with the binary outcome variable, Diabetes_binary, which indicates the presence or absence of diabetes. By examining these variables, this analysis aims to uncover patterns and insights that may inform predictive modeling for diabetes risk.\n\n#Loading Libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\n\n#Loading our data.\nbeetus_data&lt;-read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Changing to factors and adding names.  \nbeetus_data &lt;- beetus_data |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, labels = c(\"No Diabetes\", \"Pre/Diabetes\")),\n    HighBP = factor(HighBP, labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, labels = c(\"No High Cholesterol\", \"High Cholesterol\")),\n    Smoker = factor(Smoker, labels = c(\"Non-Smoker\", \"Smoker\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No Physical Activity\", \"Physical Activity\")),\n\n    Sex = factor(Sex, labels = c(\"Female\", \"Male\")),\n    GenHlth = factor(GenHlth, levels=1:5, labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    Education = factor(Education,levels=1:6, labels = c(\n      \"Never Attended School or only kindergarten\",\n      \"Grades 1-8\",\n      \"Grades 9-11\",\n      \"Grade 12/GED\",\n      \"Some College/Technical School\",\n      \"College Graduate\"\n    )),\n    Income = factor(Income,levels=1:8, labels = c(\n      \"Less than $10,000\",\n      \"$10,000 to $15,000\",\n      \"$15,000 to $20,000\",\n      \"$20,000 to $25,000\",\n      \"$25,000 to $35,000\",\n      \"$35,000 to $50,000\",\n      \"$50,000 to $75,000\",\n      \"$75,000 or more\"\n    )),\n    Age = factor(Age,levels=1:13, labels = c(\n      \"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n      \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\",\n      \"70-74\", \"75-79\", \"80 or older\"\n    ))\n  )\n#Variables we're interested in\nbeetus_filtered &lt;- beetus_data |&gt;\n  select(Diabetes_binary,HighBP,HighChol,PhysActivity,BMI,Age,Sex,GenHlth)\n\nLet’s take a look at the structure of our data and check if there’s any missing values.\n\n#Quick look at data types\nstr(beetus_filtered)\n\ntibble [253,680 × 8] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary: Factor w/ 2 levels \"No Diabetes\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP         : Factor w/ 2 levels \"No High BP\",\"High BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol       : Factor w/ 2 levels \"No High Cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ PhysActivity   : Factor w/ 2 levels \"No Physical Activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ BMI            : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Age            : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Sex            : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ GenHlth        : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n\n#Checking for Missing Data\nbeetus_filtered |&gt;\n  is.na()|&gt;\n  colSums()\n\nDiabetes_binary          HighBP        HighChol    PhysActivity             BMI \n              0               0               0               0               0 \n            Age             Sex         GenHlth \n              0               0               0 \n\n\nNo missing values. Let’s check some numerical summaries for BMI."
  },
  {
    "objectID": "EDA.html#numeric",
    "href": "EDA.html#numeric",
    "title": "EDA",
    "section": "Numeric",
    "text": "Numeric\n\nbeetus_data |&gt;\n  select(where(is.numeric)) |&gt;\n  summary()\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\n\nggplot(beetus_data, aes(x = BMI, fill = Diabetes_binary)) +\n  geom_bar() \n\n\n\n\n\n\n\nggplot(beetus_data, aes(x = Diabetes_binary,y = BMI, fill = Diabetes_binary)) +\n  geom_violin() +\n  labs(\n    title = \"Violin Plot of BMI by Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"BMI\",\n    fill = \"Diabetes Status\"\n  )\n\n\n\n\n\n\n\nggplot(beetus_data, aes(x = MentHlth, fill = Diabetes_binary)) +\n  geom_bar(position=\"dodge\") +\n  labs(\n    title = \"Density Curve for Mental Health by Diabetes Status\",\n    x = \"Mental Health (Score)\",\n    y = \"Count\",\n    fill = \"Diabetes Status\"\n  )\n\n\n\n\n\n\n\nggplot(beetus_data, aes(x = PhysHlth, fill = Diabetes_binary)) +\n  geom_bar(position=\"dodge\") +\n  labs(\n    title = \"Density Curve for Physical Health by Diabetes Status\",\n    x = \"Phys Health (Score)\",\n    y = \"Count\",\n    fill = \"Diabetes Status\"\n  )\n\n\n\n\n\n\n\n\n\n#Correlation Matrix\nbeetus_data |&gt;\nselect(where(is.numeric)) |&gt;\ncor() |&gt;\nround(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000"
  },
  {
    "objectID": "EDA.html#categorical",
    "href": "EDA.html#categorical",
    "title": "EDA",
    "section": "Categorical",
    "text": "Categorical\n\ncont_tables &lt;- lapply(names(beetus_data)[-which(names(beetus_data) == \"Diabetes_binary\")], function(var) {\n  table(beetus_data[[var]], beetus_data$Diabetes_binary)\n})\n\nnames(cont_tables) &lt;- names(beetus_data)[-which(names(beetus_data) == \"Diabetes_binary\")]\n\ncont_tables\n\n$HighBP\n            \n             No Diabetes Pre/Diabetes\n  No High BP      136109         8742\n  High BP          82225        26604\n\n$HighChol\n                     \n                      No Diabetes Pre/Diabetes\n  No High Cholesterol      134429        11660\n  High Cholesterol          83905        23686\n\n$CholCheck\n                      \n                       No Diabetes Pre/Diabetes\n  No Cholesterol Check        9229          241\n  Cholesterol Check         209105        35105\n\n$BMI\n    \n     No Diabetes Pre/Diabetes\n  12           6            0\n  13          19            2\n  14          37            4\n  15         120           12\n  16         328           20\n  17         728           48\n  18        1720           83\n  19        3833          135\n  20        6086          241\n  21        9376          479\n  22       12952          691\n  23       14697          913\n  24       18081         1469\n  25       15695         1451\n  26       18560         2002\n  27       21849         2757\n  28       14294         2251\n  29       12659         2231\n  30       12251         2322\n  31       10163         2112\n  32        8354         2120\n  33        6908         2040\n  34        5494         1687\n  35        4131         1444\n  36        3393         1240\n  37        3029         1118\n  38        2385         1012\n  39        2056          855\n  40        1534          724\n  41        1141          518\n  42        1127          512\n  43         989          511\n  44         697          346\n  45         517          302\n  46         471          279\n  47         404          218\n  48         304          180\n  49         250          166\n  50         224          148\n  51         155           98\n  52         129           86\n  53         152           85\n  54          65           48\n  55         104           65\n  56          66           43\n  57          61           25\n  58          36           35\n  59          32           22\n  60          38           25\n  61          21           14\n  62          27           16\n  63          16           18\n  64          16            8\n  65           9           10\n  66           4            9\n  67           9            6\n  68           8            6\n  69           6            3\n  70          10            5\n  71          44            5\n  72           7            7\n  73          44            3\n  74          15            1\n  75          46            6\n  76           3            0\n  77          48            7\n  78           0            1\n  79          62            4\n  80           1            1\n  81          42            7\n  82          31            6\n  83           1            1\n  84          39            5\n  85           0            1\n  86           1            0\n  87          52            9\n  88           2            0\n  89          25            3\n  90           1            0\n  91           1            0\n  92          27            5\n  95          11            1\n  96           1            0\n  98           4            3\n\n$Smoker\n            \n             No Diabetes Pre/Diabetes\n  Non-Smoker      124228        17029\n  Smoker           94106        18317\n\n$Stroke\n           \n            No Diabetes Pre/Diabetes\n  No Stroke      211310        32078\n  Stroke           7024         3268\n\n$HeartDiseaseorAttack\n     \n      No Diabetes Pre/Diabetes\n  No       202319        27468\n  Yes       16015         7878\n\n$PhysActivity\n                      \n                       No Diabetes Pre/Diabetes\n  No Physical Activity       48701        13059\n  Physical Activity         169633        22287\n\n$Fruits\n     \n      No Diabetes Pre/Diabetes\n  No        78129        14653\n  Yes      140205        20693\n\n$Veggies\n     \n      No Diabetes Pre/Diabetes\n  No        39229         8610\n  Yes      179105        26736\n\n$HvyAlcoholConsump\n     \n      No Diabetes Pre/Diabetes\n  No       204910        34514\n  Yes       13424          832\n\n$AnyHealthcare\n     \n      No Diabetes Pre/Diabetes\n  No        10995         1422\n  Yes      207339        33924\n\n$NoDocbcCost\n     \n      No Diabetes Pre/Diabetes\n  No       200722        31604\n  Yes       17612         3742\n\n$GenHlth\n           \n            No Diabetes Pre/Diabetes\n  Excellent       44159         1140\n  Very Good       82703         6381\n  Good            62189        13457\n  Fair            21780         9790\n  Poor             7503         4578\n\n$MentHlth\n    \n     No Diabetes Pre/Diabetes\n  0       152277        23403\n  1         7726          812\n  2        11546         1508\n  3         6457          924\n  4         3300          489\n  5         7807         1223\n  6          824          164\n  7         2695          405\n  8          529          110\n  9           78           13\n  10        5309         1064\n  11          38            3\n  12         331           67\n  13          33            8\n  14         969          198\n  15        4482         1023\n  16          74           14\n  17          43           11\n  18          77           20\n  19          12            4\n  20        2701          663\n  21         179           48\n  22          52           11\n  23          30            8\n  24          27            6\n  25         915          273\n  26          38            7\n  27          67           12\n  28         270           57\n  29         128           30\n  30        9320         2768\n\n$PhysHlth\n    \n     No Diabetes Pre/Diabetes\n  0       143312        16740\n  1        10200         1188\n  2        12736         2028\n  3         7206         1289\n  4         3779          763\n  5         6308         1314\n  6         1048          282\n  7         3795          743\n  8          650          159\n  9          143           36\n  10        4305         1290\n  11          48           12\n  12         449          129\n  13          52           16\n  14        2114          473\n  15        3621         1295\n  16          78           34\n  17          69           27\n  18         117           35\n  19          19            3\n  20        2356          917\n  21         524          139\n  22          47           23\n  23          40           16\n  24          57           15\n  25         942          394\n  26          47           22\n  27          78           21\n  28         379          143\n  29         141           74\n  30       13674         5726\n\n$DiffWalk\n     \n      No Diabetes Pre/Diabetes\n  No       188780        22225\n  Yes       29554        13121\n\n$Sex\n        \n         No Diabetes Pre/Diabetes\n  Female      123563        18411\n  Male         94771        16935\n\n$Age\n             \n              No Diabetes Pre/Diabetes\n  18-24              5622           78\n  25-29              7458          140\n  30-34             10809          314\n  35-39             13197          626\n  40-44             15106         1051\n  45-49             18077         1742\n  50-54             23226         3088\n  55-59             26569         4263\n  60-64             27511         5733\n  65-69             25636         6558\n  70-74             18392         5141\n  75-79             12577         3403\n  80 or older       14154         3209\n\n$Education\n                                            \n                                             No Diabetes Pre/Diabetes\n  Never Attended School or only kindergarten         127           47\n  Grades 1-8                                        2860         1183\n  Grades 9-11                                       7182         2296\n  Grade 12/GED                                     51684        11066\n  Some College/Technical School                    59556        10354\n  College Graduate                                 96925        10400\n\n$Income\n                    \n                     No Diabetes Pre/Diabetes\n  Less than $10,000         7428         2383\n  $10,000 to $15,000        8697         3086\n  $15,000 to $20,000       12426         3568\n  $20,000 to $25,000       16081         4054\n  $25,000 to $35,000       21379         4504\n  $35,000 to $50,000       31179         5291\n  $50,000 to $75,000       37954         5265\n  $75,000 or more          83190         7195\n\n\nLet’s make some graphs as well.\n#distributions for bmi/age etc… clean up titles\n\n#Showing plots of variables with 2 factor levels\ntwofact_plot&lt;- beetus_data |&gt;\n  #Select variables with only 2 factor levels for clean plotting\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) == 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n#some scaling issues\nggplot(twofact_plot, aes(x = Value, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~ Variable, scales = \"free_x\") + \n  #tilted for readability\n  theme(axis.text.x = element_text(angle = 10))\n\n\n\n\n\n\n\n#Plots for more than 2 factor levels\nmultifact_data &lt;- beetus_data |&gt;\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) &gt; 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n# Create individual plots for each variable\nplots &lt;- list() # Empty list to store plots\n# Get unique variable names\nunique_variables &lt;- unique(multifact_data$Variable) \nfor (var in unique_variables) {\n  plot &lt;- multifact_data |&gt;\n    filter(Variable == var) |&gt; \n    ggplot(aes(x = Value, fill = Diabetes_binary)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n      title = paste(\"Distribution of\", var, \"by Diabetes Status\"),\n      x = var,\n      y = \"Count\",\n      fill = \"Diabetes Status\"\n    ) +\n    \n    theme(axis.text.x = element_text(angle = 10))\n  # Store the plot in the list\n  plots[[var]] &lt;- plot\n}\nplots[[unique_variables[1]]]\n\n\n\n\n\n\n\nplots[[unique_variables[2]]]\n\n\n\n\n\n\n\nplots[[unique_variables[3]]]\n\n\n\n\n\n\n\nplots[[unique_variables[4]]]\n\n\n\n\n\n\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html#classification",
    "href": "Modeling.html#classification",
    "title": "Modeling",
    "section": "Classification",
    "text": "Classification\n#explain what it is etc…\n\ntree_rec &lt;- recipe(Diabetes_binary ~., data = beetus_train) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes())\n\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n=20,\n                          cost_complexity = tune()) |&gt; \n                          set_engine(\"rpart\") |&gt;\n                          set_mode(\"classification\")\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          #adjust here\n                          levels = c(3,3))\n\ntree_fits &lt;- tree_wkf |&gt;\n  tune_grid(resamples = beetus_folds,\n            metrics=metric_set(mn_log_loss),\n            grid = tree_grid)\n\nWarning: package 'rpart' was built under R version 4.3.3\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") \n\n# A tibble: 9 × 8\n  cost_complexity tree_depth .metric     .estimator  mean     n  std_err .config\n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n1    0.0000000001          1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n2    0.00000316            1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n3    0.1                   1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n4    0.0000000001          8 mn_log_loss binary     0.369     5 0.00882  Prepro…\n5    0.00000316            8 mn_log_loss binary     0.369     5 0.00882  Prepro…\n6    0.1                   8 mn_log_loss binary     0.404     5 0.000720 Prepro…\n7    0.0000000001         15 mn_log_loss binary     0.360     5 0.000578 Prepro…\n8    0.00000316           15 mn_log_loss binary     0.360     5 0.000578 Prepro…\n9    0.1                  15 mn_log_loss binary     0.404     5 0.000720 Prepro…\n\n\n\n#Selecting best fit\ntree_best_params &lt;- select_best(tree_fits,metric=\"mn_log_loss\")\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit &lt;- tree_final_wkf |&gt; \n  last_fit(beetus_split, metrics = metric_set(accuracy,mn_log_loss))\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.860 Preprocessor1_Model1\n2 mn_log_loss binary         0.362 Preprocessor1_Model1\n\n\n\ntree_final_model &lt;- extract_workflow(tree_final_fit)\ntree_final_model %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\n#add coefficietns and stuff"
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nRandom forest is a type of ensemble model where many models are generated using bootstrap sampling of every permutation of variable choices(similar to trees but with randomness) which are then combined to fit a model. This method is good for emphasizing the importance of each classification. However it is much more computationally intensive.\n\n#Random Forest Recipe \nrf_rec &lt;- recipe(Diabetes_binary ~., data = beetus_train) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes())\n\n#Engine\nrf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine(\"ranger\",\n             #I like to think that this is helping.\n             num.threads=parallel::detectCores(),\n             importance = \"impurity\") |&gt;\n      set_mode(\"classification\")\n#Workflow\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(rf_rec) |&gt;\n  add_model(rf_spec)\n\n\n#Tuning Parameters & Fitting\nrf_fit &lt;- rf_wkf |&gt;\n  tune_grid(resamples = beetus_folds,\n            #adjust here\n  grid = 7,\n  metrics = metric_set(accuracy, mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#Fitted Model Metrics\nrf_fit |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\")\n\n# A tibble: 7 × 7\n   mtry .metric     .estimator  mean     n  std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1    17 mn_log_loss binary     0.355     5 0.00156  Preprocessor1_Model1\n2    11 mn_log_loss binary     0.331     5 0.00107  Preprocessor1_Model2\n3    13 mn_log_loss binary     0.337     5 0.00136  Preprocessor1_Model3\n4     5 mn_log_loss binary     0.319     5 0.000752 Preprocessor1_Model4\n5     9 mn_log_loss binary     0.326     5 0.00100  Preprocessor1_Model5\n6    19 mn_log_loss binary     0.371     5 0.00206  Preprocessor1_Model6\n7     3 mn_log_loss binary     0.322     5 0.000580 Preprocessor1_Model7\n\n\n\n#Choosing Best Model\nrf_best_param &lt;-select_best(rf_fit,metric=\"mn_log_loss\")\nrf_best_param\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     5 Preprocessor1_Model4\n\n#Final Workflow\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_param)\n#Final Fit\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(beetus_split,metrics=metric_set(accuracy,mn_log_loss))\nrf_final_fit |&gt;\n    collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.865 Preprocessor1_Model1\n2 mn_log_loss binary         0.321 Preprocessor1_Model1\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 mn_log_loss binary         0.338 Preprocessor1_Model1\n\n\nBased on our models, the random forest seems to be the better fitting model with a lower log loss metric of 0.321 with mtry = 5 vs the classification tree’s 0.338 with tree depth of 4. The random forest has a slightly higher accuracy as well((True Positives + True Negatives)/Total Predictions)."
  },
  {
    "objectID": "Modeling.html#modeling",
    "href": "Modeling.html#modeling",
    "title": "Modeling",
    "section": "Modeling:",
    "text": "Modeling:\nIn the EDA page we explored the Diabetes Health Indicator’s Dataset. We were interested in exploring biological markers variables influencing the participant’s risk of diabetes. Primarily the variables we were interested in were: -If the participant has High Blood Pressure (Yes/No) -If the participant has High Cholesterol (Yes/No) -If the participant does physical activity (Yes/No) -The participant’s BMI (Integer) -The participant’s Age (Integer) -The participant’s Gender (M/F) -The participants perception of their overall health (Excellent/Good/Fair/Poor) We will fit two models in interest, a classification tree and random forest. We have split our data into a 70/30 training/test set and using a 5 fold cross-validation to improve variability. Our goal is the find the best fitting model.\n\n#Loading our data.\nbeetus_data&lt;-read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Changing to factors and adding names.  \nbeetus_data &lt;- beetus_data |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, labels = c(\"No Diabetes\", \"Pre/Diabetes\")),\n    HighBP = factor(HighBP, labels = c(\"No High BP\", \"High BP\")),\n    HighChol = factor(HighChol, labels = c(\"No High Cholesterol\", \"High Cholesterol\")),\n    Smoker = factor(Smoker, labels = c(\"Non-Smoker\", \"Smoker\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No Physical Activity\", \"Physical Activity\")),\n\n    Sex = factor(Sex, labels = c(\"Female\", \"Male\")),\n    GenHlth = factor(GenHlth, levels=1:5, labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    Education = factor(Education,levels=1:6, labels = c(\n      \"Never Attended School or only kindergarten\",\n      \"Grades 1-8\",\n      \"Grades 9-11\",\n      \"Grade 12/GED\",\n      \"Some College/Technical School\",\n      \"College Graduate\"\n    )),\n    Income = factor(Income,levels=1:8, labels = c(\n      \"Less than $10,000\",\n      \"$10,000 to $15,000\",\n      \"$15,000 to $20,000\",\n      \"$20,000 to $25,000\",\n      \"$25,000 to $35,000\",\n      \"$35,000 to $50,000\",\n      \"$50,000 to $75,000\",\n      \"$75,000 or more\"\n    )),\n    Age = factor(Age,levels=1:13, labels = c(\n      \"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\",\n      \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\",\n      \"70-74\", \"75-79\", \"80 or older\"\n    ))\n  )\n#Variables we're interested in\nbeetus_filtered &lt;- beetus_data |&gt;\n  select(Diabetes_binary,HighBP,HighChol,PhysActivity,BMI,Age,Sex,GenHlth)\n\n\nset.seed(10)\n#Splitting data into training/test\nbeetus_split&lt;- initial_split(beetus_filtered,prop=0.7)\nbeetus_train&lt;- training(beetus_split)\nbeetus_test&lt;- testing(beetus_split)\n#Cross Validation\nbeetus_folds &lt;- vfold_cv(beetus_train, 5)"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\nTree based methods such as classification trees make predictions about which class/category an observation belongs to based on its features. Basically turning it into a binary decision. The final nodes are leaves and each leaf presents a classification (IE: Has Diabetes or Does not Have Diabetes). These models are easier to interpret but are sensitive to variability in data. Below we will conduct a classification tree analysis.\n\n#Creating recipe.  Setting dummy variables/normalization\ntree_rec &lt;- recipe(Diabetes_binary ~., data = beetus_train) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes())\n\n#Setting Engine\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n=20,\n                          cost_complexity = tune()) |&gt; \n                          set_engine(\"rpart\") |&gt;\n                          set_mode(\"classification\")\n#Workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(tree_rec) |&gt;\n  add_model(tree_mod)\n\n#Tuning parameters\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          #adjust here\n                          levels = c(3,3))\n#Fitting our model\ntree_fits &lt;- tree_wkf |&gt;\n  tune_grid(resamples = beetus_folds,\n            metrics=metric_set(mn_log_loss),\n            grid = tree_grid)\n\nWarning: package 'rpart' was built under R version 4.3.3\n\n#Model performance metric\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") \n\n# A tibble: 9 × 8\n  cost_complexity tree_depth .metric     .estimator  mean     n  std_err .config\n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n1    0.0000000001          1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n2    0.00000316            1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n3    0.1                   1 mn_log_loss binary     0.404     5 0.000720 Prepro…\n4    0.0000000001          8 mn_log_loss binary     0.337     5 0.000980 Prepro…\n5    0.00000316            8 mn_log_loss binary     0.337     5 0.000980 Prepro…\n6    0.1                   8 mn_log_loss binary     0.404     5 0.000720 Prepro…\n7    0.0000000001         15 mn_log_loss binary     0.337     5 0.00163  Prepro…\n8    0.00000316           15 mn_log_loss binary     0.337     5 0.00163  Prepro…\n9    0.1                  15 mn_log_loss binary     0.404     5 0.000720 Prepro…\n\n\nWe will choose the best model primarily based on the log loss metric.\n\n#Selecting best fit\ntree_best_params &lt;- select_best(tree_fits,metric=\"mn_log_loss\")\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config             \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;               \n1    0.0000000001          8 Preprocessor1_Model4\n\n#Final Workflow\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n#Final Fit\ntree_final_fit &lt;- tree_final_wkf |&gt; \n  last_fit(beetus_split, metrics = metric_set(accuracy,mn_log_loss))\n#Final Fit Metrics\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 mn_log_loss binary         0.338 Preprocessor1_Model1\n\n\nNow a tree diagram showing our variable contributions.\n\ntree_final_model &lt;- extract_workflow(tree_final_fit)\ntree_final_model %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot::rpart.plot(roundint = FALSE)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\n\ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 177576 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 177576 24735 No Diabetes (0.86070753 0.13929247)  \n    2) HighBP_High.BP&lt; 0.1429436 101352  6072 No Diabetes (0.94008998 0.05991002)  \n      4) GenHlth_Fair&lt; 1.132413 93637  4715 No Diabetes (0.94964597 0.05035403)  \n        8) GenHlth_Good&lt; 0.43857 67766  2239 No Diabetes (0.96695983 0.03304017)  \n         16) GenHlth_Poor&lt; 2.133344 65230  1708 No Diabetes (0.97381573 0.02618427) *\n         17) GenHlth_Poor&gt;=2.133344 2536   531 No Diabetes (0.79061514 0.20938486)  \n           34) BMI&lt; 0.7684429 2060   356 No Diabetes (0.82718447 0.17281553) *\n           35) BMI&gt;=0.7684429 476   175 No Diabetes (0.63235294 0.36764706)  \n             70) HighChol_High.Cholesterol&lt; 0.1532992 248    68 No Diabetes (0.72580645 0.27419355)  \n              140) Age_X75.79&lt; 1.796788 234    59 No Diabetes (0.74786325 0.25213675)  \n                280) Age_X70.74&lt; 1.40739 217    49 No Diabetes (0.77419355 0.22580645) *\n                281) Age_X70.74&gt;=1.40739 17     7 Pre/Diabetes (0.41176471 0.58823529) *\n              141) Age_X75.79&gt;=1.796788 14     5 Pre/Diabetes (0.35714286 0.64285714) *\n             71) HighChol_High.Cholesterol&gt;=0.1532992 228   107 No Diabetes (0.53070175 0.46929825)  \n              142) BMI&lt; 1.973665 161    67 No Diabetes (0.58385093 0.41614907)  \n                284) Age_X35.39&lt; 1.967956 153    62 No Diabetes (0.59477124 0.40522876) *\n                285) Age_X35.39&gt;=1.967956 8     3 Pre/Diabetes (0.37500000 0.62500000) *\n              143) BMI&gt;=1.973665 67    27 Pre/Diabetes (0.40298507 0.59701493)  \n                286) PhysActivity_Physical.Activity&gt;=-0.5965222 22     9 No Diabetes (0.59090909 0.40909091) *\n                287) PhysActivity_Physical.Activity&lt; -0.5965222 45    14 Pre/Diabetes (0.31111111 0.68888889) *\n        9) GenHlth_Good&gt;=0.43857 25871  2476 No Diabetes (0.90429438 0.09570562)  \n         18) HighChol_High.Cholesterol&lt; 0.1532992 16959  1196 No Diabetes (0.92947697 0.07052303)  \n           36) BMI&lt; 0.6177901 13469   787 No Diabetes (0.94156953 0.05843047) *\n           37) BMI&gt;=0.6177901 3490   409 No Diabetes (0.88280802 0.11719198)  \n             74) Age_X75.79&lt; 1.796788 3412   382 No Diabetes (0.88804220 0.11195780) *\n             75) Age_X75.79&gt;=1.796788 78    27 No Diabetes (0.65384615 0.34615385)  \n              150) PhysActivity_Physical.Activity&lt; -0.5965222 32     5 No Diabetes (0.84375000 0.15625000) *\n              151) PhysActivity_Physical.Activity&gt;=-0.5965222 46    22 No Diabetes (0.52173913 0.47826087)  \n                302) Sex_Male&lt; 0.1221331 27    11 No Diabetes (0.59259259 0.40740741) *\n                303) Sex_Male&gt;=0.1221331 19     8 Pre/Diabetes (0.42105263 0.57894737) *\n         19) HighChol_High.Cholesterol&gt;=0.1532992 8912  1280 No Diabetes (0.85637343 0.14362657)  \n           38) BMI&lt; 0.4671374 6532   797 No Diabetes (0.87798530 0.12201470) *\n           39) BMI&gt;=0.4671374 2380   483 No Diabetes (0.79705882 0.20294118)  \n             78) Age_X65.69&lt; 1.119261 2133   395 No Diabetes (0.81481481 0.18518519) *\n             79) Age_X65.69&gt;=1.119261 247    88 No Diabetes (0.64372470 0.35627530)  \n              158) BMI&lt; 2.425623 235    81 No Diabetes (0.65531915 0.34468085) *\n              159) BMI&gt;=2.425623 12     5 Pre/Diabetes (0.41666667 0.58333333) *\n      5) GenHlth_Fair&gt;=1.132413 7715  1357 No Diabetes (0.82410888 0.17589112)  \n       10) HighChol_High.Cholesterol&lt; 0.1532992 4654   614 No Diabetes (0.86807048 0.13192952)  \n         20) BMI&lt; -0.1354734 2321   204 No Diabetes (0.91210685 0.08789315) *\n         21) BMI&gt;=-0.1354734 2333   410 No Diabetes (0.82426061 0.17573939)  \n           42) Age_X70.74&lt; 1.40739 2232   369 No Diabetes (0.83467742 0.16532258)  \n             84) Age_X75.79&lt; 1.796788 2137   336 No Diabetes (0.84277024 0.15722976)  \n              168) Age_X80.or.older&lt; 1.713999 2024   299 No Diabetes (0.85227273 0.14772727) *\n              169) Age_X80.or.older&gt;=1.713999 113    37 No Diabetes (0.67256637 0.32743363)  \n\n...\nand 106 more lines."
  },
  {
    "objectID": "EDA.html#numeric-variables",
    "href": "EDA.html#numeric-variables",
    "title": "EDA",
    "section": "Numeric Variables",
    "text": "Numeric Variables\n\nbeetus_filtered |&gt;\n  select(where(is.numeric)) |&gt;\n  summary()\n\n      BMI       \n Min.   :12.00  \n 1st Qu.:24.00  \n Median :27.00  \n Mean   :28.38  \n 3rd Qu.:31.00  \n Max.   :98.00  \n\n\nBMI seems slightly skewed. Let’s graph it vs our diabetes binary variable.\n\nggplot(beetus_filtered, aes(x = BMI, fill = Diabetes_binary)) +\n  geom_bar() \n\n\n\n\n\n\n\nggplot(beetus_filtered, aes(x = Diabetes_binary,y = BMI, fill = Diabetes_binary)) +\n  geom_violin() +\n  labs(\n    title = \"Violin Plot of BMI by Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"BMI\",\n    fill = \"Diabetes Status\"\n  )\n\n\n\n\n\n\n\n\nOn visual inspection, there does seem to be a difference in our samples.\nNow let’s look at our categorical variables with contingency tables."
  },
  {
    "objectID": "EDA.html#categorical-variables",
    "href": "EDA.html#categorical-variables",
    "title": "EDA",
    "section": "Categorical Variables",
    "text": "Categorical Variables\n\ncont_tables &lt;- lapply(names(beetus_filtered)[-which(names(beetus_filtered) == \"Diabetes_binary\")], function(var) {\n  table(beetus_filtered[[var]], beetus_filtered$Diabetes_binary)\n})\n\nnames(cont_tables) &lt;- names(beetus_filtered)[-which(names(beetus_filtered) == \"Diabetes_binary\")]\n\ncont_tables\n\n$HighBP\n            \n             No Diabetes Pre/Diabetes\n  No High BP      136109         8742\n  High BP          82225        26604\n\n$HighChol\n                     \n                      No Diabetes Pre/Diabetes\n  No High Cholesterol      134429        11660\n  High Cholesterol          83905        23686\n\n$PhysActivity\n                      \n                       No Diabetes Pre/Diabetes\n  No Physical Activity       48701        13059\n  Physical Activity         169633        22287\n\n$BMI\n    \n     No Diabetes Pre/Diabetes\n  12           6            0\n  13          19            2\n  14          37            4\n  15         120           12\n  16         328           20\n  17         728           48\n  18        1720           83\n  19        3833          135\n  20        6086          241\n  21        9376          479\n  22       12952          691\n  23       14697          913\n  24       18081         1469\n  25       15695         1451\n  26       18560         2002\n  27       21849         2757\n  28       14294         2251\n  29       12659         2231\n  30       12251         2322\n  31       10163         2112\n  32        8354         2120\n  33        6908         2040\n  34        5494         1687\n  35        4131         1444\n  36        3393         1240\n  37        3029         1118\n  38        2385         1012\n  39        2056          855\n  40        1534          724\n  41        1141          518\n  42        1127          512\n  43         989          511\n  44         697          346\n  45         517          302\n  46         471          279\n  47         404          218\n  48         304          180\n  49         250          166\n  50         224          148\n  51         155           98\n  52         129           86\n  53         152           85\n  54          65           48\n  55         104           65\n  56          66           43\n  57          61           25\n  58          36           35\n  59          32           22\n  60          38           25\n  61          21           14\n  62          27           16\n  63          16           18\n  64          16            8\n  65           9           10\n  66           4            9\n  67           9            6\n  68           8            6\n  69           6            3\n  70          10            5\n  71          44            5\n  72           7            7\n  73          44            3\n  74          15            1\n  75          46            6\n  76           3            0\n  77          48            7\n  78           0            1\n  79          62            4\n  80           1            1\n  81          42            7\n  82          31            6\n  83           1            1\n  84          39            5\n  85           0            1\n  86           1            0\n  87          52            9\n  88           2            0\n  89          25            3\n  90           1            0\n  91           1            0\n  92          27            5\n  95          11            1\n  96           1            0\n  98           4            3\n\n$Age\n             \n              No Diabetes Pre/Diabetes\n  18-24              5622           78\n  25-29              7458          140\n  30-34             10809          314\n  35-39             13197          626\n  40-44             15106         1051\n  45-49             18077         1742\n  50-54             23226         3088\n  55-59             26569         4263\n  60-64             27511         5733\n  65-69             25636         6558\n  70-74             18392         5141\n  75-79             12577         3403\n  80 or older       14154         3209\n\n$Sex\n        \n         No Diabetes Pre/Diabetes\n  Female      123563        18411\n  Male         94771        16935\n\n$GenHlth\n           \n            No Diabetes Pre/Diabetes\n  Excellent       44159         1140\n  Very Good       82703         6381\n  Good            62189        13457\n  Fair            21780         9790\n  Poor             7503         4578\n\n\nFrom the contingency table for HighBP, we observe a higher proportion of individuals with diabetes who have high blood pressure compared to those without diabetes. This reinforces the connection between hypertension and diabetes.\nLet’s make some graphs now.\n\n#Showing plots of variables with 2 factor levels\ntwofact_plot&lt;- beetus_filtered |&gt;\n  #Select variables with only 2 factor levels for clean plotting\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) == 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n#some scaling issues\nggplot(twofact_plot, aes(x = Value, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~ Variable, scales = \"free_x\") + \n  #tilted for readability\n  theme(axis.text.x = element_text(angle = 10))\n\n\n\n\n\n\n\n#Plots for more than 2 factor levels\nmultifact_data &lt;- beetus_filtered |&gt;\n  select(Diabetes_binary, where(~ is.factor(.) && nlevels(.) &gt; 2)) |&gt;\n  pivot_longer(\n    cols = -Diabetes_binary, \n    names_to = \"Variable\",   \n    values_to = \"Value\"      \n  )\n# Create individual plots for each variable\nplots &lt;- list() # Empty list to store plots\n# Get unique variable names\nunique_variables &lt;- unique(multifact_data$Variable) \nfor (var in unique_variables) {\n  plot &lt;- multifact_data |&gt;\n    filter(Variable == var) |&gt; \n    ggplot(aes(x = Value, fill = Diabetes_binary)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n      title = paste(\"Distribution of\", var, \"by Diabetes Status\"),\n      x = var,\n      y = \"Count\",\n      fill = \"Diabetes Status\"\n    ) +\n    \n    theme(axis.text.x = element_text(angle = 10))\n  # Store the plot in the list\n  plots[[var]] &lt;- plot\n}\nplots[[unique_variables[1]]]\n\n\n\n\n\n\n\nplots[[unique_variables[2]]]\n\n\n\n\n\n\n\n\nGeneral health seems to have a visual difference as well.\n\nConclusion\nThis analysis highlights that BMI, HighBP, and self-reported health ratings (GenHlth) appear to have differences. These variables could serve as valuable inputs for predictive modeling. Our modeling section will further explore these variables to see if they are significant.\nClick here for the Modeling Page"
  }
]